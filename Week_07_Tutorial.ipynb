{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMDslkLS3uj71aNgCpycEHG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nbchan/INMR96-Digital-Health-and-Data-Analytics/blob/main/Week_07_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frajfwsbe055"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "For this tutorial, instead of individual bite-sized exercises, a modified copy of the notebook on Exploratory Data Analysis, Training, Evaluating and Tuning Models (I) would be given. You would need to complete certain parts of the codes yourself (indicated with `## YOUR CODE HERE ##`). For the given parts of the code, try understanding them as much as possible instead of simply mindlessly executing all of them. Refer to the original notebook for solutions.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnGIpIj4cJaq"
      },
      "source": [
        "# 1. Setting up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmkFn7Yrck1t"
      },
      "source": [
        "**Packages for data handling and visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMy8PYCmW22F"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "sns.set_theme()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R0W3t47iq_O"
      },
      "source": [
        "**Packages for data analysis and modelling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoHOrDu5ivPv"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, classification_report, ConfusionMatrixDisplay, RocCurveDisplay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYZWbwV3cqHa"
      },
      "source": [
        "**Import the intermediate dataset and Authenication for Google Drive access**\n",
        "\n",
        "If you saved the intermediate dataset in your Google Drive by following all the steps in the previous tutorial, you can grant Colab access to your Google Drive and import the intermediate dataset to the current notebook.\n",
        "\n",
        "Alternatively, when you are working on your own analysis, you may also put everything (e.g. codes for extracting data from BigQuery; exploring data; preparing and cleaning data; building models) in a single notebook. In that case, you do not need to import the dataset from your Google Drive - simply continue with the cleaned dataset in your existing notebook environment. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyV_r_xhbuxw"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive', force_remount = True) # you would need to authenicate yourself here\n",
        "\n",
        "gdrive_rootpath = '/content/gdrive/MyDrive/' \n",
        "# if you saved the file inside a folder in your Google Drive (instead of the base path), \n",
        "# you would need to append the folder name to the above"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have followed the previous tutorial and execute all codes, a file named 'mimic_in_hosp_death_clean.csv' should appear in your Google Drive. In that case you can directly import it into the current notebook. Otherwise, you can download the intermediate dataset using the link below."
      ],
      "metadata": {
        "id": "E3PwyWV-wvUd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VosxWnKTbwcD"
      },
      "source": [
        "if os.path.exists(gdrive_rootpath + 'mimic_in_hosp_death_clean.csv'):\n",
        "  print('Importing file from Google Drive...')\n",
        "  df = pd.read_csv(gdrive_rootpath + 'mimic_in_hosp_death_clean.csv')\n",
        "else:\n",
        "  print('Importing file from external link...')\n",
        "  df = pd.read_csv('https://dl.dropboxusercontent.com/s/0g9rio6jz5zb8ow/mimic_in_hosp_death_clean.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bMdrT9jecVR"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLSCWB-Wnixu"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# 2. Exploratory Data Analysis (EDA)\n",
        "\n",
        "The goals of EDA are to:\n",
        "\n",
        "1. **understand** the data and uncover any problems inherent in the dataset\n",
        "2. determine if the given dataset is **relevant and sufficient** to answer a specific research question or train a decision support system based on it\n",
        "3. determine the data **pre-processing or feature engineering** steps required for model training (as discussed in the previous tutorial)\n",
        "4. **refine** the research problem and/or objectives based on what you have learned about the data\n",
        "\n",
        "Like many other steps in data analysis, EDA is an iterative process. Here, we will introduce some tools you may use when exploring a dataset. While not demostrated below, one package that may come in handy in EDA is [Pandas Profiling](https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/). "
      ],
      "metadata": {
        "id": "3GO9RsCq0Dn9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Prediction Target: `IN_HOSP_DEATH`"
      ],
      "metadata": {
        "id": "meYBqubM3_0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the number of patients who died within the dataset? What is the in-hospital death rate?"
      ],
      "metadata": {
        "id": "rIHZpS1xBcXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE ##"
      ],
      "metadata": {
        "id": "Rz6Y26OzzrsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 2.2. Categorical features\n",
        "\n",
        "We can tally and visualise each feature by category using bar charts. You may also apply statistical tests to see if there are significant differences between groups.\n",
        "\n",
        "For simple visualizations in Python, the package [seaborn](https://seaborn.pydata.org/) may come in handy.\n"
      ],
      "metadata": {
        "id": "EnN1-ldJ60Qd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`GENDER`**"
      ],
      "metadata": {
        "id": "FBQ4rxKf8dFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the average in-hospital mortality rate by gender?"
      ],
      "metadata": {
        "id": "wkKANCdq8on_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE ##\n",
        "# hint: use .groupby() followed by .mean()"
      ],
      "metadata": {
        "id": "JYEcQ8AM8i4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualise it using `sns.barplot()`"
      ],
      "metadata": {
        "id": "NbSAeiq28xvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE ##"
      ],
      "metadata": {
        "id": "W_DDwIX88wT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the average in-hospital mortality rate by each of the following?\n",
        "\n",
        "* `ADMISSION_TYPE`\n",
        "* `INSURANCE`\n",
        "\n",
        "For each feature, also visualise it using `sns.barplot()`."
      ],
      "metadata": {
        "id": "GrWq2LbLCBhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ADMISSION_TYPE\n",
        "## YOUR CODE HERE ##"
      ],
      "metadata": {
        "id": "9F0j70UwCbhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## INSURANCE\n",
        "## YOUR CODE HERE ##"
      ],
      "metadata": {
        "id": "TdSvtrxqCeFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmiJJhLnhK3t"
      },
      "source": [
        "## 2.3. Numerical features\n",
        "\n",
        "For univariate analysis, we can calculate basic statistics and visualise them using box plots, histograms and density plots. For multivariate, we can use scatter plots (for two numerical features) and side-by-side histograms (for one numerical and one categorical feature)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`AGE`**"
      ],
      "metadata": {
        "id": "9wDCIgwdATFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate some basic statistics for the variable `AGE`."
      ],
      "metadata": {
        "id": "7Z_2B8MMCoDt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5JLm5MShMDR"
      },
      "source": [
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayDAF4KOdjOL"
      },
      "source": [
        "Visualise the age distribution using `sns.histplot()` and `sns.boxplot()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKrHYmC3ZDLL"
      },
      "source": [
        "# histogram\n",
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuakUV65Z5I6"
      },
      "source": [
        "# box plot\n",
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot a box plot to show the age distribution by `IN_HOSP_DEATH`"
      ],
      "metadata": {
        "id": "Z-qvNXR2C9Zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# box plot by category\n",
        "## YOUR CODE HERE ##"
      ],
      "metadata": {
        "id": "fES-_bQKAhXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gg0bwgGax0z"
      },
      "source": [
        "# side-by-side histrograms\n",
        "g = sns.FacetGrid(df, col = 'IN_HOSP_DEATH', sharey = False, height = 6) # height = 6 specifies the plot size here\n",
        "g.map(sns.histplot, 'AGE', bins = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mpdxE2RaV5G"
      },
      "source": [
        "**Discussion**: \n",
        "\n",
        "* What can you observe from the figure above?\n",
        "* Based on the figure above, shall we remove the infants (e.g. `AGE` < 1) from our training dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aK0r-wwAThs"
      },
      "source": [
        "**`DIAG_COUNT`**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualise the distribution of `DIAG_COUNT` using `sns.histplot()` and `sns.boxplot()`."
      ],
      "metadata": {
        "id": "87q543hGDcYg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha7M0KEEDrnu"
      },
      "source": [
        "# histogram\n",
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqyWTgVCDrnu"
      },
      "source": [
        "# box plot\n",
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3t56_UOcxHR"
      },
      "source": [
        "g = sns.FacetGrid(df, col = 'IN_HOSP_DEATH', sharey = False, height = 6)\n",
        "g.map(sns.histplot, 'DIAG_COUNT', bins = 20, kde = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdnL-K_blExs"
      },
      "source": [
        "As a reference for you, the following code plots the distributions of all numerical features for the two patient groups using a `For` loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH6wxvbdlYW5"
      },
      "source": [
        "numerical_feaures = ['AGE', 'DIAG_COUNT', 'CALLOUT_COUNT_DAY', 'PRES_COUNT_DAY', \n",
        "                     'PROC_COUNT_DAY', 'CPT_COUNT_DAY', 'LAB_COUNT_DAY',\n",
        "                     'INPUTS_CV_COUNT_DAY', 'INPUTS_MV_COUNT_DAY', 'OUTPUT_COUNT_DAY', \n",
        "                     'TRANSFER_COUNT_DAY', 'MICRO_COUNT_DAY', 'LOS', 'LOS_ICU']\n",
        "\n",
        "for col_name in numerical_feaures:\n",
        "  print(col_name)\n",
        "  g = sns.FacetGrid(df, col = 'IN_HOSP_DEATH', sharey = False, height = 6)\n",
        "  g.map(sns.histplot, col_name, bins = 20, kde = True)\n",
        "  plt.show()\n",
        "  print('_'*20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# 3. Training a Logistic Regression Model"
      ],
      "metadata": {
        "id": "GuexQoL6ENqs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciDSdMSXjI9V"
      },
      "source": [
        "## 3.1. Train-test Split\n",
        "\n",
        "* Help **mitigate overfitting** (model learns to fit the noise and error terms in the data) while we train machine learning models\n",
        "* Allow us to report an **unbiased performance metric** using data unseen by the model\n",
        "* A 70-30 or 80-20 split is usually the most common. \n",
        "\n",
        "![](https://miro.medium.com/max/694/1*tBErXYVvTw2jSUYK7thU2A.png)\n",
        "\n",
        "([Source](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kNWwOYsnnF5"
      },
      "source": [
        "`IN_HOSP_DEATH` would be our prediction target. Here, let's define a list of 38 column names for features/inputs we would use in the model as not all columns are appropriate (e.g. `SUBJECT_ID`). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwtYw-H2nj-Z"
      },
      "source": [
        "features_list = ['GENDER_F', 'AGE', 'LOS', 'LOS_ICU', \n",
        "                 'CALLOUT_COUNT_DAY', 'PRES_COUNT_DAY', 'PROC_COUNT_DAY',\n",
        "                 'CPT_COUNT_DAY', 'LAB_COUNT_DAY', 'INPUTS_CV_COUNT_DAY',\n",
        "                 'INPUTS_MV_COUNT_DAY', 'OUTPUT_COUNT_DAY', 'TRANSFER_COUNT_DAY',\n",
        "                 'MICRO_COUNT_DAY', \n",
        "                 'ADMISSION_TYPE_ELECTIVE', 'ADMISSION_TYPE_EMERGENCY', 'ADMISSION_TYPE_NEWBORN', 'ADMISSION_TYPE_URGENT', \n",
        "                 'RELIGION_CATHOLIC', 'RELIGION_NOT SPECIFIED', 'RELIGION_UNOBTAINABLE', 'RELIGION_OTHERS', \n",
        "                 'INSURANCE_Medicare', 'INSURANCE_Private', 'INSURANCE_Medicaid', 'INSURANCE_OTHERS',\n",
        "                 'MARITAL_STATUS_MARRIED', 'MARITAL_STATUS_SINGLE', 'MARITAL_STATUS_UNKNOWN (DEFAULT)', 'MARITAL_STATUS_OTHERS',\n",
        "                 'LANGUAGE_ENGL', 'LANGUAGE_SPAN', 'LANGUAGE_RUSS', 'LANGUAGE_OTHERS',\n",
        "                 'ETHNICITY_WHITE', 'ETHNICITY_BLACK/AFRICAN AMERICAN', 'ETHNICITY_UNKNOWN/NOT SPECIFIED', 'ETHNICITY_OTHERS']\n",
        "\n",
        "len(features_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Then, create a DataFrame (`X`) containing input features only as well as a Series (`y`) containing our prediction target. "
      ],
      "metadata": {
        "id": "xEEq6odyFt7H"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnPEJnMjq8dG"
      },
      "source": [
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, use `train_test_split()` from the package [Scikit-learn](https://scikit-learn.org/stable/) to perform a *80-20 stratified* train-test split. \n",
        "\n",
        "Check out the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) of the function for examples and usage. Note that the function outputs four things: the input and output datasets for training and testing respectively. "
      ],
      "metadata": {
        "id": "VCDqkhj2F8fk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6MFgGhUjYwb"
      },
      "source": [
        "## YOUR CODE HERE ##\n",
        "X_train, X_test, y_train, y_test = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using `.shape`, make sure the dimensions of `X_train` and `X_test` are (47180, 38) and (11796, 38) respectively"
      ],
      "metadata": {
        "id": "tcswwVOCFFWn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhSH-NEhrcVI"
      },
      "source": [
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_C9DfnRrsjS"
      },
      "source": [
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIzFO247rmjB"
      },
      "source": [
        "As a result, our training and test set would include 47,180 and 11,796 admissions respectively. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eor-Oq3x7iio"
      },
      "source": [
        "## 3.2. Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq_fZIosiaFl"
      },
      "source": [
        "![](https://static.javatpoint.com/tutorial/machine-learning/images/linear-regression-vs-logistic-regression.png)\n",
        "\n",
        "([Source](https://www.javatpoint.com/linear-regression-vs-logistic-regression-in-machine-learning))\n",
        "\n",
        "In this example, we would be utilizing the package package [Scikit-learn](https://scikit-learn.org/stable/user_guide.html) heavily for modelling. In Scikit-learn, the general flow for training and using a model can be simplified into 3 steps:\n",
        "\n",
        "1. **Specify a model to be trained**\n",
        "  * Choose a type of model based on your task and dataset. A full list of available models in the package can be found [here](https://scikit-learn.org/stable/modules/classes.html).\n",
        "  * Set the hyperparameters of the model. \n",
        "  * Assign the model to a variable.\n",
        "2. **Train the model**\n",
        "  * Call the `.fit()` function using your cleaned train dataset.\n",
        "3. **Make predictions**\n",
        "  * Call the `.predict()` function using your cleaned test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGiQXnaF7k-U"
      },
      "source": [
        "# 1. Specify a model to be trained\n",
        "## YOUR CODE HERE ##\n",
        "# hint: use LogisticRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUVdAqCa7_VJ"
      },
      "source": [
        "# 2. Train the model\n",
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXJk0ZS48Jgq"
      },
      "source": [
        "# 3. Make predictions (binary)\n",
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pihaxTN1BIHc"
      },
      "source": [
        "Use `.predict_proba()` instead if you want probabilistic outputs over class outputs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPJQ8npLBCB-"
      },
      "source": [
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOvZnFB-ksjf"
      },
      "source": [
        "---\n",
        "\n",
        "## 3.3. Evaluation (binary classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC-UKsTmJMoG"
      },
      "source": [
        "There are several metrics for evaluating the binary classification performances. In general, the most common reported metric for these kinds of machine learning problems are\n",
        "\n",
        "* **F1-score**: harmonic mean of precision and recall\n",
        "* **Area under receiver operating characteristic curve (AUC)**: overall diagnostic ability across all classification probability cutoffs\n",
        "\n",
        "![binary classification metrics](https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg)\n",
        "\n",
        "([Source](https://manisha-sirsat.blogspot.com/2019/04/confusion-matrix.html))\n",
        "\n",
        "<img src='https://upload.wikimedia.org/wikipedia/commons/1/13/Roc_curve.svg' width='40%'>\n",
        "\n",
        "([Source](https://en.wikipedia.org/wiki/Receiver_operating_characteristic))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnlsu2WX8PYR"
      },
      "source": [
        "# to calculate accuracy:\n",
        "## YOUR CODE HERE ##\n",
        "# hint: use `accuracy_score()`"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to calculate F1 score:\n",
        "## YOUR CODE HERE ##\n",
        "# hint: use `f1_score()`"
      ],
      "metadata": {
        "id": "X-dMcUpaVx-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwZSc1LA8Tf3"
      },
      "source": [
        "# to display multiple classification-related metrics:\n",
        "print(classification_report(y_test, y_pred_lr, digits = 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFe6SKZG8YRE"
      },
      "source": [
        "# to visualise a confusion matrix using a heatmap:\n",
        "ConfusionMatrixDisplay.from_estimator(model_lr, X_test, y_test)\n",
        "plt.grid(False) # just to disable grid lines for this plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the colour in the above plot has little implications as the quantity of the two classes differ by too much. We can express them as ratios and percentages instead. "
      ],
      "metadata": {
        "id": "mxiHZe5nMbm7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvT6wt7D8h2K"
      },
      "source": [
        "# recall-related metrics (% of row)\n",
        "ConfusionMatrixDisplay.from_estimator(model_lr, X_test, y_test, normalize = ## YOUR CODE HERE ##) \n",
        "plt.grid(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqwWsT628lgb"
      },
      "source": [
        "# precision-related metrics (% of column)\n",
        "ConfusionMatrixDisplay.from_estimator(model_lr, X_test, y_test, normalize = ## YOUR CODE HERE ##)\n",
        "plt.grid(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3Hx-hA49EAY"
      },
      "source": [
        "# to plot an ROC:\n",
        "fig, ax = plt.subplots(figsize=(6, 6)) # modify figure size\n",
        "RocCurveDisplay.from_estimator(model_lr, X_test, y_test, ax = ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to calculate Area under ROC:\n",
        "## YOUR CODE HERE ##\n",
        "# hint: use `roc_auc_score()`\n",
        "# hint: use probabilistic predictions over class predictions"
      ],
      "metadata": {
        "id": "BPq78LguO-dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvMK4tiplLnL"
      },
      "source": [
        "**Some Observations**\n",
        "\n",
        "* Despite having an accuracy of 92.6%, the overall F1-score is around 48%. The high accuracy is due to class imbalance and the model predicted the majority class (`IN_HOSP_DEATH == 0`) correctly. \n",
        "* The recall for the positive examples is 34%, meaning that only around one-third of those who died within their hospital stay is successfully detected by the model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# 4. Training a Random Forest Model"
      ],
      "metadata": {
        "id": "2lOuFb6Bz2t_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1. Train-test Split\n",
        "\n",
        "As we have already made a train-test split when training the logistic regression model, we do not need to do this again. Having the same data split also allows for fair comparison between models."
      ],
      "metadata": {
        "id": "7uezP6H-0Zou"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MzozqJp3Vgi"
      },
      "source": [
        "---\n",
        "\n",
        "## 4.2. Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecd_EV120F2f"
      },
      "source": [
        "* A Random Forest model consists of **multiple Decision Tree** models.\n",
        "* Each decision tree consists of **levels** of nodes that represent **yes/no questions**. By following these rules given by a decision tree, each sample arrives to the end node which outputs a prediction. \n",
        "* Decision trees are trained by minimizing metrics such as gini score or **entropy**. \n",
        "* Random Forest is trained by first training multiple decision trees with different subsets of the training dataset as inputs; then **aggregate the predictions from all decision trees** via a majority vote or averaging. \n",
        "\n",
        "![Random Forest](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/rfc_vs_dt1.png)\n",
        "\n",
        "([Source](https://www.analyticsvidhya.com/blog/2020/05/decision-tree-vs-random-forest-algorithm/))\n",
        "\n",
        "We can follow the same 3-step process to train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5tJmuoF2fns"
      },
      "source": [
        "Define the configuration/hyperparameters of a random forest model. Here we specify that the model contains 200 decision trees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqmi5cLRiiOY"
      },
      "source": [
        "# 1. Specify a model to be trained\n",
        "# Also define the configuration/hyperparameters of a random forest model. \n",
        "# Here we specify that the model contains 200 decision trees.\n",
        "\n",
        "## YOUR CODE HERE ##\n",
        "# hint: use RandomForestClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjdZWia9seQG"
      },
      "source": [
        "# 2. Train the model\n",
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCT2LIRVspQm"
      },
      "source": [
        "# 3. Make predictions\n",
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use `.predict_proba()` instead if you want probabilistic outputs over class outputs."
      ],
      "metadata": {
        "id": "StcejcXe-M2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE ##"
      ],
      "metadata": {
        "id": "HQvw6z-R-C_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTRnCjeQo99E"
      },
      "source": [
        "---\n",
        "\n",
        "## 4.3. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh64-ZXb0F2g"
      },
      "source": [
        "# to calculate accuracy:\n",
        "## YOUR CODE HERE ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to calculate F1 score:\n",
        "## YOUR CODE HERE ##"
      ],
      "metadata": {
        "id": "W-VaOQ2O0F2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfQ26YfW0F2g"
      },
      "source": [
        "# to display multiple classification-related metrics:\n",
        "print(classification_report(y_test, y_pred_rf, digits = 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvx6CR3_0F2h"
      },
      "source": [
        "# to visualise a confusion matrix using a heatmap:\n",
        "# recall-related metrics (% of row)\n",
        "ConfusionMatrixDisplay.from_estimator(model_rf, X_test, y_test, normalize = 'true') \n",
        "plt.grid(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDmTEmj50F2h"
      },
      "source": [
        "# precision-related metrics (% of column)\n",
        "ConfusionMatrixDisplay.from_estimator(model_rf, X_test, y_test, normalize = 'pred')\n",
        "plt.grid(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXFS_6wa0F2h"
      },
      "source": [
        "# to plot an ROC:\n",
        "fig, ax = plt.subplots(figsize=(6, 6)) # modify figure size\n",
        "RocCurveDisplay.from_estimator(model_rf, X_test, y_test, ax = ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to calculate Area under ROC:\n",
        "## YOUR CODE HERE ##\n",
        "# hint: use probabilistic predictions over class predictions"
      ],
      "metadata": {
        "id": "CrDfANwx0F2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us compare the performance of the two models with the table below: "
      ],
      "metadata": {
        "id": "XRRNrTkR30eU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({\n",
        "    'Random Forest': [\n",
        "        accuracy_score(y_test, y_pred_rf), \n",
        "        f1_score(y_test, y_pred_rf), \n",
        "        precision_score(y_test, y_pred_rf), \n",
        "        recall_score(y_test, y_pred_rf), \n",
        "        roc_auc_score(y_test, y_pred_prob_rf[:,1])\n",
        "    ], \n",
        "    'Logistic Regression': [\n",
        "        accuracy_score(y_test, y_pred_lr), \n",
        "        f1_score(y_test, y_pred_lr), \n",
        "        precision_score(y_test, y_pred_lr), \n",
        "        recall_score(y_test, y_pred_lr), \n",
        "        roc_auc_score(y_test, y_pred_prob_lr[:,1])\n",
        "    ]\n",
        "    }, index=[\n",
        "        'Accuracy', 'F1 Score', 'Precision', 'Recall', 'ROC'\n",
        "    ])"
      ],
      "metadata": {
        "id": "tm8XLBR_2bZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Some Observations**\n",
        "\n",
        "* This model outperforms the logistic regression model we have trained last tutorial in several metrics:\n",
        "* The recall is still not optimal at 45.5%, meaning that only around half of those who died within their hospital stay is successfully detected by the model. Depending on the objectives of your model, it **could be beneficial to choose another cutoff point** for binary classification predictions rather than the default 0.5. One might prioritise recall over precision if the impact of having false negatives outweighs false positives. For example, for cancer prediction, minimising the risk of unidentified positive cases (hence delayed treatment) could outweigh the inconvenience and costs incurred by additional checkup appointments for negative cases. "
      ],
      "metadata": {
        "id": "WyAb-_xW_MxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tuning Cutoffs"
      ],
      "metadata": {
        "id": "fblQEKR54Yf5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As an example, let's lower the cutoff to 0.2 so that more patients will be classified as positive (hence higher recall at the cost of lower precision). We can use the probablistic outputs from the model (saved in `y_pred_prob_rf`) and define a new cutoff ourselves. "
      ],
      "metadata": {
        "id": "TNuIVcnEGjwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot a histogram of the probabilistic predictions of the random forest model."
      ],
      "metadata": {
        "id": "JH5pyvdNGVTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE ##\n",
        "# hint: use probabilistic predictions over class predictions"
      ],
      "metadata": {
        "id": "iPptwIMgGamH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lower the prediction cutoff to 0.2 and save it as a new variable."
      ],
      "metadata": {
        "id": "fAEPp592GnhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE ##"
      ],
      "metadata": {
        "id": "p2qPSGj_G2Fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count the number of predicted positives based on cutoffs 0.5 (the default) and 0.2."
      ],
      "metadata": {
        "id": "t8VWOF0BGwvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE ##"
      ],
      "metadata": {
        "id": "aqGg-IOjJeHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## YOUR CODE HERE ##"
      ],
      "metadata": {
        "id": "hGvflppzJig7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to display multiple classification-related metrics:\n",
        "print(classification_report(y_test, y_pred_rf_cutoff20, digits = 3))"
      ],
      "metadata": {
        "id": "lC1xcM7fHcui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# recall-related metrics (% of row)\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_rf_cutoff20, normalize = 'true') \n",
        "plt.grid(False)"
      ],
      "metadata": {
        "id": "KZLit0sqHtPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# precision-related metrics (% of column)\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_rf_cutoff20, normalize = 'pred')\n",
        "plt.grid(False)"
      ],
      "metadata": {
        "id": "mXPKg4uKIELC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As we lower the cutoff, more patients were classified as positive (613 -> 1,680), leading to a better recall (45.5% -> 75.7%) and a worse precision (84.7% -> 52.7%)"
      ],
      "metadata": {
        "id": "Goa26L0mJAtL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgSQuIWj2JVA"
      },
      "source": [
        "---\n",
        "\n",
        "## 4.4. Understanding a Random Forest Model\n",
        "\n",
        "One major strength of tree-based machine learning models is its inherent ability to easily report **feature importance**. This could be useful to finding insights in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQryJO6r3Hm5"
      },
      "source": [
        "model_rf_importance = pd.Series(## YOUR CODE HERE ##\n",
        "                                , index = features_list).sort_values(ascending=False)\n",
        "model_rf_importance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxSsX1dc3e3r"
      },
      "source": [
        "plt.figure(figsize = (10, 10))\n",
        "sns.barplot(x = model_rf_importance, y = model_rf_importance.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-5l_n25hGIw"
      },
      "source": [
        "## 4.6. Saving and Loading your trained model\n",
        "\n",
        "After training a model you might want to save your model to your Google Drive so that you do not need to re-train it next time. (As a side note, due to the random nature of most machine learning algorithms, if you did not set a random seed (`random_state`) while training, you would end up with a model with different trained parameters when you re-train a model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT3b-nFyhFeJ"
      },
      "source": [
        "import joblib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCQcVCAfizIk"
      },
      "source": [
        "To save:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn79ixExiQoJ"
      },
      "source": [
        "joblib.dump(model_rf, gdrive_rootpath + 'mimic_in_hosp_mortality_model_rf.joblib') # specify your filename here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mglo1oGMi2X7"
      },
      "source": [
        "To load:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aKNGrqaidOb"
      },
      "source": [
        "model_rf_loaded = joblib.load(gdrive_rootpath + 'mimic_in_hosp_mortality_model_rf.joblib') # specify your filename here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHez_PgUir71"
      },
      "source": [
        "model_rf_loaded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PIaRwWU58lW"
      },
      "source": [
        "## 4.7. Discussion\n",
        "\n",
        "How well will the models above translate into a decision support system in practice? Here are some issues you may think about (which is beyond the scope of training machine learning models itself):\n",
        "\n",
        "* What are the purposes or goals of the model? Where would it lie on the patient pathway? Do they align with the interests of clinicians, patients or other stakeholders? \n",
        "* Suppose we trained a reasonably reliable model. What could be the associated interventions based on the model predictions?\n",
        "* What are the limitations of the model from an operational perspective? \n",
        "  * e.g. consider the time of which the variables becomes available. Could the model deliver the predictions in a timely manner? Can this be improved? "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# Extras\n",
        "\n",
        "You may also explore the [COVID-19 worldwide dataset](https://github.com/owid/covid-19-data/blob/master/public/data/) by comparing statistics on Jan 1, 2022 across `continent`s. Here are some codes to help you get started."
      ],
      "metadata": {
        "id": "aGz_HabkSGOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_covid = pd.read_csv('https://covid.ourworldindata.org/data/owid-covid-data.csv')\n",
        "df_covid_filtered = df_covid[df_covid['date'] == '2022-01-01'] # filter by date\n",
        "df_covid_filtered = df_covid_filtered[~df_covid_filtered['iso_code'].str.startswith('OWID_')] # removes non-country locations such as \"Worldwide\", \"Asia\" and \"Low income\"\n",
        "\n",
        "df_covid_filtered"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "uyU9SVqlTHKP",
        "outputId": "677cb892-a681-436a-8d81-05eeecae24a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       iso_code continent           location        date  total_cases  \\\n",
              "1041        AFG      Asia        Afghanistan  2022-12-31     207559.0   \n",
              "3251        ALB    Europe            Albania  2022-12-31     333806.0   \n",
              "4350        DZA    Africa            Algeria  2022-12-31     271228.0   \n",
              "5443        AND    Europe            Andorra  2022-12-31      47751.0   \n",
              "6518        AGO    Africa             Angola  2022-12-31     105095.0   \n",
              "...         ...       ...                ...         ...          ...   \n",
              "254239      VNM      Asia            Vietnam  2022-12-31   11525231.0   \n",
              "256168      WLF   Oceania  Wallis and Futuna  2022-12-31       3415.0   \n",
              "258356      YEM      Asia              Yemen  2022-12-31      11945.0   \n",
              "259433      ZMB    Africa             Zambia  2022-12-31     334425.0   \n",
              "260508      ZWE    Africa           Zimbabwe  2022-12-31     259981.0   \n",
              "\n",
              "        new_cases  new_cases_smoothed  total_deaths  new_deaths  \\\n",
              "1041          9.0              35.571        7849.0         2.0   \n",
              "3251          0.0               8.143        3595.0         0.0   \n",
              "4350          5.0               4.857        6881.0         0.0   \n",
              "5443          0.0               9.286         165.0         0.0   \n",
              "6518          0.0              17.429        1930.0         0.0   \n",
              "...           ...                 ...           ...         ...   \n",
              "254239       87.0             147.000       43186.0         0.0   \n",
              "256168        0.0               0.000           7.0         0.0   \n",
              "258356        0.0               0.000        2159.0         0.0   \n",
              "259433        0.0              57.714        4024.0         0.0   \n",
              "260508        0.0               0.000        5637.0         0.0   \n",
              "\n",
              "        new_deaths_smoothed  ...  male_smokers  handwashing_facilities  \\\n",
              "1041                  0.571  ...           NaN                  37.746   \n",
              "3251                  0.000  ...          51.2                     NaN   \n",
              "4350                  0.000  ...          30.4                  83.741   \n",
              "5443                  0.000  ...          37.8                     NaN   \n",
              "6518                  0.286  ...           NaN                  26.664   \n",
              "...                     ...  ...           ...                     ...   \n",
              "254239                0.286  ...          45.9                  85.847   \n",
              "256168                0.000  ...           NaN                     NaN   \n",
              "258356                0.000  ...          29.2                  49.542   \n",
              "259433                0.714  ...          24.7                  13.938   \n",
              "260508                0.000  ...          30.7                  36.791   \n",
              "\n",
              "        hospital_beds_per_thousand  life_expectancy  human_development_index  \\\n",
              "1041                          0.50            64.83                    0.511   \n",
              "3251                          2.89            78.57                    0.795   \n",
              "4350                          1.90            76.88                    0.748   \n",
              "5443                           NaN            83.73                    0.868   \n",
              "6518                           NaN            61.15                    0.581   \n",
              "...                            ...              ...                      ...   \n",
              "254239                        2.60            75.40                    0.704   \n",
              "256168                         NaN            79.94                      NaN   \n",
              "258356                        0.70            66.12                    0.470   \n",
              "259433                        2.00            63.89                    0.584   \n",
              "260508                        1.70            61.49                    0.571   \n",
              "\n",
              "        population  excess_mortality_cumulative_absolute  \\\n",
              "1041    41128772.0                                   NaN   \n",
              "3251     2842318.0                                   NaN   \n",
              "4350    44903228.0                                   NaN   \n",
              "5443       79843.0                                   NaN   \n",
              "6518    35588996.0                                   NaN   \n",
              "...            ...                                   ...   \n",
              "254239  98186856.0                                   NaN   \n",
              "256168     11596.0                                   NaN   \n",
              "258356  33696612.0                                   NaN   \n",
              "259433  20017670.0                                   NaN   \n",
              "260508  16320539.0                                   NaN   \n",
              "\n",
              "        excess_mortality_cumulative  excess_mortality  \\\n",
              "1041                            NaN               NaN   \n",
              "3251                            NaN               NaN   \n",
              "4350                            NaN               NaN   \n",
              "5443                            NaN               NaN   \n",
              "6518                            NaN               NaN   \n",
              "...                             ...               ...   \n",
              "254239                          NaN               NaN   \n",
              "256168                          NaN               NaN   \n",
              "258356                          NaN               NaN   \n",
              "259433                          NaN               NaN   \n",
              "260508                          NaN               NaN   \n",
              "\n",
              "        excess_mortality_cumulative_per_million  \n",
              "1041                                        NaN  \n",
              "3251                                        NaN  \n",
              "4350                                        NaN  \n",
              "5443                                        NaN  \n",
              "6518                                        NaN  \n",
              "...                                         ...  \n",
              "254239                                      NaN  \n",
              "256168                                      NaN  \n",
              "258356                                      NaN  \n",
              "259433                                      NaN  \n",
              "260508                                      NaN  \n",
              "\n",
              "[219 rows x 67 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2740df16-4971-4dd3-a9d7-8f5f47cb1980\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>iso_code</th>\n",
              "      <th>continent</th>\n",
              "      <th>location</th>\n",
              "      <th>date</th>\n",
              "      <th>total_cases</th>\n",
              "      <th>new_cases</th>\n",
              "      <th>new_cases_smoothed</th>\n",
              "      <th>total_deaths</th>\n",
              "      <th>new_deaths</th>\n",
              "      <th>new_deaths_smoothed</th>\n",
              "      <th>...</th>\n",
              "      <th>male_smokers</th>\n",
              "      <th>handwashing_facilities</th>\n",
              "      <th>hospital_beds_per_thousand</th>\n",
              "      <th>life_expectancy</th>\n",
              "      <th>human_development_index</th>\n",
              "      <th>population</th>\n",
              "      <th>excess_mortality_cumulative_absolute</th>\n",
              "      <th>excess_mortality_cumulative</th>\n",
              "      <th>excess_mortality</th>\n",
              "      <th>excess_mortality_cumulative_per_million</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1041</th>\n",
              "      <td>AFG</td>\n",
              "      <td>Asia</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>207559.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>35.571</td>\n",
              "      <td>7849.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.571</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37.746</td>\n",
              "      <td>0.50</td>\n",
              "      <td>64.83</td>\n",
              "      <td>0.511</td>\n",
              "      <td>41128772.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3251</th>\n",
              "      <td>ALB</td>\n",
              "      <td>Europe</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>333806.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.143</td>\n",
              "      <td>3595.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>51.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.89</td>\n",
              "      <td>78.57</td>\n",
              "      <td>0.795</td>\n",
              "      <td>2842318.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4350</th>\n",
              "      <td>DZA</td>\n",
              "      <td>Africa</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>271228.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.857</td>\n",
              "      <td>6881.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>30.4</td>\n",
              "      <td>83.741</td>\n",
              "      <td>1.90</td>\n",
              "      <td>76.88</td>\n",
              "      <td>0.748</td>\n",
              "      <td>44903228.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5443</th>\n",
              "      <td>AND</td>\n",
              "      <td>Europe</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>47751.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.286</td>\n",
              "      <td>165.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>37.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>83.73</td>\n",
              "      <td>0.868</td>\n",
              "      <td>79843.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6518</th>\n",
              "      <td>AGO</td>\n",
              "      <td>Africa</td>\n",
              "      <td>Angola</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>105095.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.429</td>\n",
              "      <td>1930.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.286</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26.664</td>\n",
              "      <td>NaN</td>\n",
              "      <td>61.15</td>\n",
              "      <td>0.581</td>\n",
              "      <td>35588996.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254239</th>\n",
              "      <td>VNM</td>\n",
              "      <td>Asia</td>\n",
              "      <td>Vietnam</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>11525231.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>147.000</td>\n",
              "      <td>43186.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.286</td>\n",
              "      <td>...</td>\n",
              "      <td>45.9</td>\n",
              "      <td>85.847</td>\n",
              "      <td>2.60</td>\n",
              "      <td>75.40</td>\n",
              "      <td>0.704</td>\n",
              "      <td>98186856.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256168</th>\n",
              "      <td>WLF</td>\n",
              "      <td>Oceania</td>\n",
              "      <td>Wallis and Futuna</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>3415.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>79.94</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11596.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258356</th>\n",
              "      <td>YEM</td>\n",
              "      <td>Asia</td>\n",
              "      <td>Yemen</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>11945.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2159.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>29.2</td>\n",
              "      <td>49.542</td>\n",
              "      <td>0.70</td>\n",
              "      <td>66.12</td>\n",
              "      <td>0.470</td>\n",
              "      <td>33696612.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259433</th>\n",
              "      <td>ZMB</td>\n",
              "      <td>Africa</td>\n",
              "      <td>Zambia</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>334425.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57.714</td>\n",
              "      <td>4024.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.714</td>\n",
              "      <td>...</td>\n",
              "      <td>24.7</td>\n",
              "      <td>13.938</td>\n",
              "      <td>2.00</td>\n",
              "      <td>63.89</td>\n",
              "      <td>0.584</td>\n",
              "      <td>20017670.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260508</th>\n",
              "      <td>ZWE</td>\n",
              "      <td>Africa</td>\n",
              "      <td>Zimbabwe</td>\n",
              "      <td>2022-12-31</td>\n",
              "      <td>259981.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>5637.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>30.7</td>\n",
              "      <td>36.791</td>\n",
              "      <td>1.70</td>\n",
              "      <td>61.49</td>\n",
              "      <td>0.571</td>\n",
              "      <td>16320539.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>219 rows  67 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2740df16-4971-4dd3-a9d7-8f5f47cb1980')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2740df16-4971-4dd3-a9d7-8f5f47cb1980 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2740df16-4971-4dd3-a9d7-8f5f47cb1980');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ABKsxHLhb_i"
      },
      "source": [
        "# References\n",
        "\n",
        "* [Which machine learning algorithm should I use?](https://blogs.sas.com/content/subconsciousmusings/2020/12/09/machine-learning-algorithm-use/)\n",
        "![](https://blogs.sas.com/content/subconsciousmusings/files/2017/04/machine-learning-cheet-sheet-2.png)\n",
        "* [Decision Tree vs. Random Forest  Which Algorithm Should you Use?](https://www.analyticsvidhya.com/blog/2020/05/decision-tree-vs-random-forest-algorithm/)\n",
        "* [Train/Test Split and Cross Validation in Python](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)\n"
      ]
    }
  ]
}